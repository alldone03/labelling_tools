{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Make Sense Backend on Google Colab\n",
                "\n",
                "Gunakan notebook ini untuk menjalankan backend Make Sense (YOLOv8) di Google Colab. \n",
                "Ini memungkinkan Anda memanfaatkan GPU gratis Google untuk inferensi yang lebih cepat.\n",
                "\n",
                "### Langkah-langkah:\n",
                "1.  Jalankan sel instalasi dependensi.\n",
                "2.  Upload model YOLO custom Anda (`best.pt`) ke file storage Colab (di panel kiri).\n",
                "3.  Masukkan Authtoken Ngrok Anda (Daftar gratis di [ngrok.com](https://dashboard.ngrok.com/get-started/your-authtoken)).\n",
                "4.  Jalankan server.\n",
                "5.  Salin URL publik (misal: `https://xxxx-xx-xx-xx-xx.ngrok-free.app`) dan masukkan ke frontend Make Sense."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install fastapi uvicorn python-multipart ultralytics pyngrok nest-asyncio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Define API & App (Main Code)\n",
                "import os\n",
                "from fastapi import FastAPI, UploadFile, File, Form\n",
                "from fastapi.middleware.cors import CORSMiddleware\n",
                "from ultralytics import YOLO\n",
                "from PIL import Image\n",
                "import io\n",
                "import numpy as np\n",
                "import cv2\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "# Configure CORS\n",
                "app.add_middleware(\n",
                "    CORSMiddleware,\n",
                "    allow_origins=[\"*\"],  # Allow all origins for Colab usage\n",
                "    allow_credentials=True,\n",
                "    allow_methods=[\"*\"],\n",
                "    allow_headers=[\"*\"],\n",
                ")\n",
                "\n",
                "# Load YOLO model\n",
                "# PASTIKAN ANDA SUDAH MENGUPLOAD 'best.pt' KE FILE COLAB (/content/best.pt)\n",
                "model_path = \"/content/best.pt\"\n",
                "try:\n",
                "    if os.path.exists(model_path):\n",
                "        model = YOLO(model_path)\n",
                "        print(\"YOLO model loaded successfully!\")\n",
                "    else:\n",
                "        model = None\n",
                "        print(f\"Model not found at {model_path}. Please upload 'best.pt'. Using standard yolov8n.pt as fallback.\")\n",
                "        model = YOLO(\"yolov8n.pt\")\n",
                "except Exception as e:\n",
                "    print(f\"Error loading YOLO model: {e}\")\n",
                "    model = None\n",
                "\n",
                "@app.get(\"/\")\n",
                "async def root():\n",
                "    return {\"status\": \"online\", \"message\": \"Make Sense Backend is running on Colab!\"}\n",
                "\n",
                "@app.post(\"/annotate\")\n",
                "async def annotate_image(file: UploadFile = File(...)):\n",
                "    if not model:\n",
                "        return {\"success\": False, \"error\": \"Model not loaded\"}\n",
                "\n",
                "    try:\n",
                "        # Read image file\n",
                "        contents = await file.read()\n",
                "        image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
                "        img_array = np.array(image)\n",
                "\n",
                "        # Run inference\n",
                "        results = model(img_array)\n",
                "\n",
                "        # Process results\n",
                "        annotations = []\n",
                "        for result in results:\n",
                "            boxes = result.boxes.cpu().numpy()\n",
                "            for i, box in enumerate(boxes):\n",
                "                x1, y1, x2, y2 = box.xyxy[0]\n",
                "                confidence = float(box.conf[0])\n",
                "                class_id = int(box.cls[0])\n",
                "                try:\n",
                "                    class_name = model.names[class_id]\n",
                "                except:\n",
                "                    class_name = str(class_id)\n",
                "\n",
                "                # Calculate bbox format [center_x, center_y, width, height] used by Frontend\n",
                "                w = x2 - x1\n",
                "                h = y2 - y1\n",
                "                x = x1 + w / 2\n",
                "                y = y1 + h / 2\n",
                "\n",
                "                annotations.append({\n",
                "                    \"bbox\": [float(x), float(y), float(w), float(h)],\n",
                "                    \"class\": class_name,\n",
                "                    \"score\": confidence\n",
                "                })\n",
                "\n",
                "        return {\n",
                "            \"success\": True,\n",
                "            \"annotations\": annotations,\n",
                "            \"count\": len(annotations)\n",
                "        }\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing image: {e}\")\n",
                "        return {\"success\": False, \"error\": str(e)}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Run Server with Ngrok\n",
                "import nest_asyncio\n",
                "from pyngrok import ngrok\n",
                "import uvicorn\n",
                "\n",
                "nest_asyncio.apply()\n",
                "\n",
                "# --- CONFIGURATION ---\n",
                "# Masukkan token Ngrok Anda di sini\n",
                "NGROK_AUTH_TOKEN = \"MASUKKAN_TOKEN_ANDA_DISINI\"\n",
                "# ---------------------\n",
                "\n",
                "if NGROK_AUTH_TOKEN == \"MASUKKAN_TOKEN_ANDA_DISINI\":\n",
                "    print(\"‚ö†Ô∏è PERINGATAN: Anda belum memasukkan Ngrok Auth Token.\")\n",
                "    print(\"Silakan daftar di https://dashboard.ngrok.com/get-started/your-authtoken dan tempel token Anda di atas.\")\n",
                "else:\n",
                "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
                "\n",
                "    # Kill existing tunnels\n",
                "    ngrok.kill()\n",
                "\n",
                "    # Open a HTTP tunnel on port 8000\n",
                "    public_url_obj = ngrok.connect(8000)\n",
                "    public_url = public_url_obj.public_url\n",
                "    \n",
                "    print(\"=\"*50)\n",
                "    print(f\"üöÄ PUBLIC URL ANDA: {public_url}\")\n",
                "    print(\"Copy URL di atas dan paste ke 'Backend URL' di popup Make Sense.\")\n",
                "    print(\"=\"*50)\n",
                "\n",
                "    # Run the server\n",
                "    uvicorn.run(app, port=8000)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}